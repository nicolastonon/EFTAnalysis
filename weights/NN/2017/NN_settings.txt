Start of NN training :23-Jul-2020 (00:04:14)

OPTIONS
----------------- 
TTree --> result
eventWeightName --> 
strategy --> CARL_singlePoint
splitTrainEventFrac --> 0.75
nEpochs --> 20
nHiddenLayers --> 4
nNeuronsAllHiddenLayers --> 100
nNeuronsPerHiddenLayer --> [128, 64, 32, 16]
activInputLayer --> tanh
activHiddenLayers --> lrelu
use_normInputLayer --> True
use_batchNorm --> True
dropoutRate --> 0.3
regularizer --> ['l2', 0.0001]
optimizer --> Adam
learnRate --> 0.001
maxEventsPerClass --> -1
nEventsTot_train --> -1
nEventsTot_test --> -1
batchSizeClass --> 512
refPoint --> rwgt_ctz_2
listOperatorsParam --> ['cpq3']
nPointsPerOperator --> 20
minWC --> -3
maxWC --> 3
nEventsPerPoint --> 2000
batchSizeEFT --> 512
score_lossWeight --> 1
regress_onLogr --> False
targetVarIdx --> []
comparVarIdx --> -1
cuts --> 1
makeValPlotsOnly --> False
testToy1D --> False
parametrizedNN --> False
regress --> False
nofOutputNodes --> 1
maxEvents --> -1
batchSize --> 512
loss --> binary_crossentropy
metrics --> binary_accuracy
NN_strategy --> MVA_EFT
----------------- 

End of NN training and evaluation :23-juil.-2020 (00:06:07)
