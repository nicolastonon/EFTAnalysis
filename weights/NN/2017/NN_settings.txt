Start of NN training :20-Jun-2020 (18:57:53)

OPTIONS
----------------- 
strategy --> regressor
eventWeightName --> eventWeight/1000
splitTrainEventFrac --> 0.8
nEpochs --> 150
nHiddenLayers --> 5
nNeuronsPerLayer --> 80
activInputLayer --> tanh
activHiddenLayers --> relu
use_normInputLayer --> True
use_batchNorm --> True
dropoutRate --> 0.0
regularizer --> ['', 0.0001]
maxEventsPerClass --> 1000
nEventsTot_train --> -1
nEventsTot_test --> -1
batchSizeClass --> 512
listOperatorsParam --> ['ctz']
nPointsPerOperator --> 100
minWC --> -10
maxWC --> 10
nEventsPerPoint --> 1000
batchSizeEFT --> 5000
refPoint --> SM
score_lossWeight --> 1
regress_onLogr --> False
targetVarIdx --> 0
comparVarIdx --> 1
cuts --> 1
makeValPlotsOnly --> True
parameterizedNN --> False
regress --> True
nofOutputNodes --> 1
maxEvents --> 1000
batchSize --> 512
loss --> mean_absolute_error
optim --> <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7faae85a15d0>
metrics --> mean_absolute_error
----------------- 

End of NN training and evaluation :20-juin-2020 (18:58:05)
