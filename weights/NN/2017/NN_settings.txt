Start of NN training :07-Jul-2020 (15:26:24)

OPTIONS
----------------- 
TTree --> result
eventWeightName --> 
strategy --> CARL
splitTrainEventFrac --> 0.8
nEpochs --> 60
nHiddenLayers --> 3
nNeuronsPerLayer --> 100
activInputLayer --> 
activHiddenLayers --> relu
use_normInputLayer --> True
use_batchNorm --> True
dropoutRate --> 0.2
regularizer --> ['l2', 0.0001]
optimizer --> Adam
learnRate --> 0.001
maxEventsPerClass --> -1
nEventsTot_train --> -1
nEventsTot_test --> -1
batchSizeClass --> 512
listOperatorsParam --> ['ctz', 'ctw']
nPointsPerOperator --> 20
minWC --> -5
maxWC --> 5
nEventsPerPoint --> 3000
batchSizeEFT --> 756
refPoint --> SM
score_lossWeight --> 1
regress_onLogr --> False
targetVarIdx --> []
comparVarIdx --> -1
cuts --> 1
makeValPlotsOnly --> True
parameterizedNN --> True
regress --> False
nofOutputNodes --> 1
maxEvents --> 3000
batchSize --> 756
loss --> binary_crossentropy
metrics --> AUC
NN_strategy --> MVA_param
----------------- 

